---
title: "Lab_09R"
author: "36-600"
date: "Fall 2022"
output: 
  html_document:
    toc: no
    toc_float: no
    theme: spacelab
---

To answer the questions below, it will help you to refer to the class notes and to Sections 8.1 and 8.3.1-8.3.2 of ISLR 1ed. *Note, however, that we use the rpart package to create trees, which ISLR does not use.* So ISLR is best used for looking up background details.

# Regression Trees

## Data, Part I

We'll begin by importing the heart-disease dataset and log-transforming the response variable, `Cost`:
```{r}
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
summary(df)
df
```

## Question 1

Split the data into training and test sets. Call these `df.train` and `df.test`. You can copy whatever code you used to perform splitting in Lab 06R, Question 1. You should reuse the random number seed: this will allow you to compare your MSE for the decision tree model to your MSE for your linear model (Lab 06R, Question 5).
```{r}
# FILL ME IN
set.seed(10)
s=sample(nrow(df),round(0.7*nrow(df)))
df.train=df[s,]
df.test=df[-s,]
```

## Question 2

Learn a regression tree model and report the test-set MSE. How does this MSE compare with what you observed for the linear model? Is it lower? If so, then the (inherently more flexible) nonlinear regression tree model is adapting better to the geometry of the data than the (inherently less flexible) linear model...with the tradeoff that inferential ability is reduced. (But not eliminated, as we'll see.)
```{r}
# FILL ME IN
library(rpart)
rpart.out = rpart(Cost~.,data=df.train)
pred= predict(rpart.out,newdata=df.test)
mean((df.test$Cost-pred)^2)
```
```
FILL ME IN
Yes, the MSE I get from here is lower than what I get from linear model.
```

## Question 3

Visualize the tree. Install the package `rpart.plot` and run its namesake function while inputting the results of your tree fit. If you were of a mind to do inference, you'd look to see what variables lie at the top of the tree: these are presumably the ones with the most statistical information. (Note that because this is a regression tree, the `extra` argument to `rpart.plot()` won't necessarily be useful here.)
```{r}
# FILL ME IN
library(rpart.plot)
rpart.plot(rpart.out)
```

## Question 4

Create a diagnostic plot, specifically, the test-set predicted responses ($y$-axis) versus the test-set observed responses ($x$-axis). The predictions were generated in Question 2. For enhanced readability, be sure to set the $x$ limits and the $y$ limits to be the same, and add a line of slope one to the plot. Does the plot seem strange to you? Remember that for a decision tree, this "strangeness" is a feature, not a bug. If you don't know what causes it, call us over.
```{r}
# FILL ME IN
plot(df.test$Cost,pred,xlim=c(0,10),ylim=c(0,10))+abline(a=0,b=1)
```

## Question 5

Run `plotcp()` with the output of your call to `rplot()` to see if the tree needs pruned. (Yes, it should be "needs to be pruned," but you're in Pittsburgh.) As a reminder, you are looking for the leftmost point that lies below the dotted line. If this is not the last point (the point farthest to the right), then `plotcp()` is trying to tell you to prune the tree. Note that depending on how you split the data, you may or may not see evidence that pruning is necessary.

Note that even if pruning is deemed necessary, you do not need to do that pruning here. You would, if necessary, go back to the code given in today's notes to extract the pruned tree, which you can then use to, e.g., compute an MSE.
```{r}
# FILL ME IN
plotcp(rpart.out)
```

---

# Classification Trees

Now we turn our attention to classification trees.

## Data, Part II

We will now load in the data on political movements that you looked at in the logistic regression lab:
```{r}
file.path <- "http://www.stat.cmu.edu/~pfreeman/movement.Rdata"
load(url(file.path))
f <- function(variable,level0="NO",level1="YES") {
  n <- length(variable)
  new.variable <- rep(level0,n)
  w <- which(variable==1)
  new.variable[w] <- level1
  return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
rm(file.path,id.half,id,predictors.half)
summary(predictors)
summary(response)
```

## Question 6

Split the data! Feel free to recreate what you did for Question 2 of the Lab 08R.
```{r}
# FILL ME IN
set.seed(303)
s<- sample(nrow(predictors),round(0.7*nrow(predictors)))
pred.train<-predictors[s,]
pred.test<-predictors[-s,]
resp.train<-response[s]
resp.test<-response[-s]
```

## Question 7

Your next job is to learn a classification tree. Do that, and output a confusion matrix. (Note that the use of the `predict()` function might be, for you, a little different here: use `type="class"` as an argument, so that the output is not a probability but a classification. You can use the output directly when creating the confusion matrix.) What is the misclassification rate? (If you split your data in the same manner as you did for linear regression, is the MCR lower? Just make a mental note.)
```{r}
# FILL ME IN
rpart.out2 = rpart(resp.train~.,data=pred.train)
class.pred = predict(rpart.out2,newdata=pred.test, type="class")

mean(class.pred!=resp.test)
tab<-table(class.pred,resp.test)
tab
```
```
FILL ME IN
The MCR is (18+3)/65=21/65=32%, which is higher than the linear regression
```

## Question 8

Let's follow up on the material presented on Tuesday by computing the Area Under Curve (AUC) for the decision tree model. Dealing with prediction is a bit tricky as the argument change a bit from model to model, but what you'd want to do here is run

- resp.pred <- predict(rpart.out,newdata=pred.test,type="prob")[,2]

and then mimic the material presented in the notes on Tuesday to generate an AUC.
```{r}
# FILL ME IN
library(pROC)
resp.pred <- predict(rpart.out2,newdata=pred.test, type="prob")[,2]
(roc.log = roc(resp.test,resp.pred))
cat("AUC for logistic regression: ",round(roc.log$auc,3),"\n")

#The AUC is 0.71
```

## Question 9

Plot your classification tree (perhaps with the argument `extra=104` or `extra=106`) and determine if pruning is necessary using `plotcp()`. Make a mental note about the pruning...but see Question 9.
```{r}
# FILL ME IN
rpart.plot(rpart.out2, extra=104)
plotcp(rpart.out2)
#I think it needs pruned at 0.13
```

## Question 10

Here, I suspect you saw clear evidence that pruning would be useful. Go ahead, prune the tree and replot the pruned tree. Also, compute the misclassification rate: did pruning make things worse?
```{r}
# FILL ME IN
rpart.pruned <- prune(rpart.out2,cp=0.13)
class.prob <- predict(rpart.pruned,newdata=pred.test,type="class")



mean(class.prob!=resp.test)
tab<-table(class.prob,resp.test)
tab

```
```
FILL ME IN
The MCR went down a little ((15+5)/65=20/65*100=30% vs. 32%). So pruning did not make things worse.
```
